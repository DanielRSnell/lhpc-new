---
title: Monitoring & Metrics
description: Comprehensive observability, performance monitoring, and compliance reporting for LaunchHPC orchestration platform.
---

## Observability Overview

LaunchHPC provides enterprise-grade monitoring and observability capabilities for tracking workload performance, resource utilization, cost analytics, and compliance across multi-cloud environments. The platform integrates with industry-standard monitoring tools and provides real-time insights for operational excellence.

### Monitoring Stack

LaunchHPC deploys a comprehensive monitoring stack:

```
monitoring-architecture/
├── metrics/
│   ├── prometheus/
│   ├── datadog/
│   └── custom-exporters/
├── logging/
│   ├── elasticsearch/
│   ├── fluentd/
│   └── log-aggregation/
├── tracing/
│   ├── jaeger/
│   ├── zipkin/
│   └── distributed-tracing/
├── visualization/
│   ├── grafana/
│   ├── kibana/
│   └── custom-dashboards/
└── alerting/
    ├── alertmanager/
    ├── pagerduty/
    └── notification-channels/
```

## Metrics Collection

### System Metrics

Configure comprehensive system monitoring:

```yaml title="monitoring/prometheus-config.yaml"
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: monitoring
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      evaluation_interval: 15s
      
    rule_files:
      - /etc/prometheus/rules/*.yml
      
    scrape_configs:
      # LaunchHPC Core Components
      - job_name: 'launchhpc-controller'
        static_configs:
          - targets: ['launchhpc-controller:8080']
        metrics_path: /metrics
        scrape_interval: 10s
        
      - job_name: 'launchhpc-scheduler'
        static_configs:
          - targets: ['launchhpc-scheduler:8081']
        metrics_path: /metrics
        scrape_interval: 10s
        
      # Kubernetes Infrastructure
      - job_name: 'kubernetes-nodes'
        kubernetes_sd_configs:
          - role: node
        relabel_configs:
          - source_labels: [__address__]
            regex: '(.*):10250'
            target_label: __address__
            replacement: '${1}:9100'
            
      - job_name: 'kubernetes-pods'
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
            action: keep
            regex: true
            
      # Workload Metrics
      - job_name: 'workload-metrics'
        kubernetes_sd_configs:
          - role: pod
            namespaces:
              names: ['default', 'ai-workloads', 'hpc-workloads']
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_label_workload_type]
            action: keep
            regex: '(ai-training|hpc-compute|data-processing)'
            
    # Remote write for long-term storage
    remote_write:
      - url: "https://prometheus.launchhpc.com/api/v1/write"
        write_relabel_configs:
          - source_labels: [__name__]
            regex: 'go_.*'
            action: drop
```

### Custom Metrics

Define application-specific metrics for LaunchHPC workloads:

```go title="metrics/workload-metrics.go"
package metrics

import (
    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promauto"
)

var (
    // Workload execution metrics
    WorkloadDurationHistogram = promauto.NewHistogramVec(
        prometheus.HistogramOpts{
            Name: "launchhpc_workload_duration_seconds",
            Help: "Histogram of workload execution durations",
            Buckets: prometheus.ExponentialBuckets(1, 2, 15), // 1s to ~9h
        },
        []string{"workload_type", "framework", "provider", "region"},
    )

    WorkloadCostGauge = promauto.NewGaugeVec(
        prometheus.GaugeOpts{
            Name: "launchhpc_workload_cost_usd",
            Help: "Current cost of running workload in USD",
        },
        []string{"workload_id", "workload_type", "provider"},
    )

    ResourceUtilizationGauge = promauto.NewGaugeVec(
        prometheus.GaugeOpts{
            Name: "launchhpc_resource_utilization_percent",
            Help: "Resource utilization percentage",
        },
        []string{"resource_type", "node_id", "workload_id"},
    )

    // Scheduler metrics
    SchedulingDecisionCounter = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "launchhpc_scheduling_decisions_total",
            Help: "Total number of scheduling decisions",
        },
        []string{"decision_type", "provider", "success"},
    )

    QueueDepthGauge = promauto.NewGaugeVec(
        prometheus.GaugeOpts{
            Name: "launchhpc_queue_depth",
            Help: "Number of jobs in queue by priority",
        },
        []string{"priority", "workload_type"},
    )

    // AI optimization metrics
    AIOptimizationAccuracy = promauto.NewGaugeVec(
        prometheus.GaugeOpts{
            Name: "launchhpc_ai_optimization_accuracy",
            Help: "Accuracy of AI optimization predictions",
        },
        []string{"model_version", "optimization_type"},
    )
)

// RecordWorkloadCompletion records metrics when a workload completes
func RecordWorkloadCompletion(workloadType, framework, provider, region string, duration float64, cost float64) {
    WorkloadDurationHistogram.WithLabelValues(workloadType, framework, provider, region).Observe(duration)
    // Cost is recorded separately as it may update during execution
}
```

### Data Export

Export metrics to various external systems:

```yaml title="monitoring/metric-exporters.yaml"
apiVersion: apps/v1
kind: Deployment
metadata:
  name: launchhpc-metrics-exporter
  namespace: monitoring
spec:
  replicas: 2
  selector:
    matchLabels:
      app: metrics-exporter
  template:
    metadata:
      labels:
        app: metrics-exporter
    spec:
      containers:
        - name: datadog-exporter
          image: launchhpc/datadog-exporter:v1.2.0
          env:
            - name: DATADOG_API_KEY
              valueFrom:
                secretKeyRef:
                  name: datadog-credentials
                  key: api-key
            - name: PROMETHEUS_URL
              value: 'http://prometheus:9090'
          resources:
            requests:
              cpu: 100m
              memory: 128Mi
            limits:
              cpu: 500m
              memory: 512Mi

        - name: cloudwatch-exporter
          image: launchhpc/cloudwatch-exporter:v1.2.0
          env:
            - name: AWS_REGION
              value: 'us-west-2'
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: aws-credentials
                  key: access-key-id
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: aws-credentials
                  key: secret-access-key
          resources:
            requests:
              cpu: 100m
              memory: 128Mi
```

## Performance Monitoring

### Real-Time Dashboards

Create comprehensive Grafana dashboards for operational visibility:

```json title="dashboards/launchhpc-overview.json"
{
  "dashboard": {
    "title": "LaunchHPC Operations Overview",
    "tags": ["launchhpc", "overview"],
    "timezone": "UTC",
    "panels": [
      {
        "id": 1,
        "title": "Active Workloads",
        "type": "stat",
        "targets": [
          {
            "expr": "sum(launchhpc_workloads_active)",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "color": { "mode": "thresholds" },
            "thresholds": {
              "steps": [
                { "color": "green", "value": null },
                { "color": "yellow", "value": 80 },
                { "color": "red", "value": 100 }
              ]
            }
          }
        }
      },
      {
        "id": 2,
        "title": "Workload Success Rate",
        "type": "stat",
        "targets": [
          {
            "expr": "rate(launchhpc_workload_completions_total{status=\"success\"}[5m]) / rate(launchhpc_workload_completions_total[5m]) * 100",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "percent",
            "min": 0,
            "max": 100
          }
        }
      },
      {
        "id": 3,
        "title": "Cost per Hour by Provider",
        "type": "bargauge",
        "targets": [
          {
            "expr": "sum by (provider) (launchhpc_workload_cost_usd)",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "currencyUSD"
          }
        }
      },
      {
        "id": 4,
        "title": "Resource Utilization",
        "type": "timeseries",
        "targets": [
          {
            "expr": "avg(launchhpc_resource_utilization_percent{resource_type=\"cpu\"})",
            "legendFormat": "CPU",
            "refId": "A"
          },
          {
            "expr": "avg(launchhpc_resource_utilization_percent{resource_type=\"memory\"})",
            "legendFormat": "Memory",
            "refId": "B"
          },
          {
            "expr": "avg(launchhpc_resource_utilization_percent{resource_type=\"gpu\"})",
            "legendFormat": "GPU",
            "refId": "C"
          }
        ]
      }
    ]
  }
}
```

### Performance Analytics

Implement automated performance analysis:

```python title="analytics/performance-analyzer.py"
#!/usr/bin/env python3
"""
LaunchHPC Performance Analytics
Analyzes workload performance and generates optimization recommendations
"""

import pandas as pd
import numpy as np
from prometheus_api_client import PrometheusConnect
from datetime import datetime, timedelta
import json

class PerformanceAnalyzer:
    def __init__(self, prometheus_url: str):
        self.prom = PrometheusConnect(url=prometheus_url)

    def analyze_workload_performance(self, time_range: str = "24h") -> dict:
        """Analyze workload performance over specified time range"""

        # Get workload completion data
        completions_query = f'increase(launchhpc_workload_completions_total[{time_range}])'
        completions = self.prom.custom_query(completions_query)

        # Get resource utilization data
        cpu_util_query = f'avg_over_time(launchhpc_resource_utilization_percent{{resource_type="cpu"}}[{time_range}])'
        cpu_utilization = self.prom.custom_query(cpu_util_query)

        # Get cost data
        cost_query = f'sum_over_time(launchhpc_workload_cost_usd[{time_range}])'
        costs = self.prom.custom_query(cost_query)

        # Calculate efficiency metrics
        analysis = {
            "summary": {
                "total_workloads": sum(float(c['value'][1]) for c in completions),
                "avg_cpu_utilization": np.mean([float(u['value'][1]) for u in cpu_utilization]),
                "total_cost": sum(float(c['value'][1]) for c in costs),
                "timestamp": datetime.now().isoformat()
            },
            "recommendations": self._generate_recommendations(completions, cpu_utilization, costs),
            "trends": self._analyze_trends(time_range)
        }

        return analysis

    def _generate_recommendations(self, completions, utilization, costs) -> list:
        """Generate optimization recommendations based on performance data"""
        recommendations = []

        # CPU utilization analysis
        avg_cpu = np.mean([float(u['value'][1]) for u in utilization])
        if avg_cpu < 40:
            recommendations.append({
                "type": "resource_optimization",
                "priority": "medium",
                "message": f"CPU utilization is low ({avg_cpu:.1f}%). Consider using smaller instance types.",
                "potential_savings": "15-30%"
            })
        elif avg_cpu > 85:
            recommendations.append({
                "type": "scaling",
                "priority": "high",
                "message": f"CPU utilization is high ({avg_cpu:.1f}%). Consider scaling up or out.",
                "performance_impact": "May cause job delays"
            })

        return recommendations

    def _analyze_trends(self, time_range: str) -> dict:
        """Analyze performance trends"""
        # Implementation for trend analysis
        return {
            "cost_trend": "stable",
            "performance_trend": "improving",
            "utilization_trend": "increasing"
        }

# Usage example
if __name__ == "__main__":
    analyzer = PerformanceAnalyzer("http://prometheus:9090")
    analysis = analyzer.analyze_workload_performance("7d")
    print(json.dumps(analysis, indent=2))
```

## Cost Analytics

### Multi-Cloud Cost Tracking

Track and optimize costs across cloud providers:

```yaml title="cost-analytics/cost-tracker.yaml"
apiVersion: launchhpc.io/v1
kind: CostAnalyzer
metadata:
  name: multi-cloud-cost-tracker
  namespace: launchhpc-system
spec:
  providers:
    aws:
      enabled: true
      costExplorer:
        enabled: true
        granularity: 'HOURLY'
        metrics: ['BlendedCost', 'UsageQuantity']
        groupBy: ['SERVICE', 'INSTANCE_TYPE']

    azure:
      enabled: true
      costManagement:
        enabled: true
        scope: '/subscriptions/12345678-1234-1234-1234-123456789012'
        granularity: 'Hourly'

    gcp:
      enabled: true
      billing:
        enabled: true
        projectId: 'launchhpc-production'

  analysis:
    optimization:
      enabled: true
      spotInstanceRecommendations: true
      rightsizingRecommendations: true
      schedulingOptimizations: true

    reporting:
      frequency: 'daily'
      recipients: ['devops-team@company.com']
      formats: ['dashboard', 'email', 'slack']

    budgets:
      - name: 'monthly-hpc-budget'
        amount: 50000
        currency: 'USD'
        period: 'monthly'
        alerts:
          - threshold: 80
            type: 'email'
          - threshold: 95
            type: 'pagerduty'
```

### Cost Optimization API

```typescript title="api/cost-optimization.ts"
import { CostAnalyzer, WorkloadOptimizer } from '@launchhpc/sdk';

export class CostOptimizationService {
  private costAnalyzer: CostAnalyzer;
  private workloadOptimizer: WorkloadOptimizer;

  constructor(config: any) {
    this.costAnalyzer = new CostAnalyzer(config.costAnalyzer);
    this.workloadOptimizer = new WorkloadOptimizer(config.optimizer);
  }

  async generateCostReport(
    timeRange: string,
    groupBy: string[],
  ): Promise<CostReport> {
    const costs = await this.costAnalyzer.getCosts({
      timeRange,
      groupBy,
      includeForecasting: true,
    });

    const optimization = await this.workloadOptimizer.analyzeOptimization({
      costs,
      includeSpotInstances: true,
      includeRightsizing: true,
    });

    return {
      totalCost: costs.total,
      breakdown: costs.breakdown,
      forecast: costs.forecast,
      optimizationOpportunities: optimization.opportunities,
      potentialSavings: optimization.savings,
      recommendations: optimization.recommendations,
    };
  }

  async optimizeWorkloadCosts(workloadId: string): Promise<OptimizationPlan> {
    const workload = await this.getWorkload(workloadId);
    const historicalCosts = await this.costAnalyzer.getWorkloadCosts(
      workloadId,
      '30d',
    );

    const plan = await this.workloadOptimizer.createOptimizationPlan({
      workload,
      historicalCosts,
      constraints: {
        maxPerformanceImpact: 0.1, // 10% max performance degradation
        minCostSavings: 0.15, // 15% minimum cost savings
      },
    });

    return plan;
  }

  async trackBudgetCompliance(): Promise<BudgetStatus> {
    const budgets = await this.costAnalyzer.getBudgets();
    const currentSpend = await this.costAnalyzer.getCurrentSpend();

    return {
      budgets: budgets.map((budget) => ({
        name: budget.name,
        amount: budget.amount,
        spent: currentSpend[budget.name] || 0,
        remaining: budget.amount - (currentSpend[budget.name] || 0),
        utilizationPercent:
          ((currentSpend[budget.name] || 0) / budget.amount) * 100,
      })),
      alerts: this.generateBudgetAlerts(budgets, currentSpend),
    };
  }
}

interface CostReport {
  totalCost: number;
  breakdown: CostBreakdown[];
  forecast: CostForecast;
  optimizationOpportunities: OptimizationOpportunity[];
  potentialSavings: number;
  recommendations: string[];
}

interface OptimizationPlan {
  workloadId: string;
  currentConfiguration: any;
  optimizedConfiguration: any;
  estimatedSavings: number;
  implementationSteps: string[];
}
```

## Compliance & Reporting

### Compliance Monitoring

Ensure regulatory compliance across workloads:

```yaml title="compliance/compliance-policies.yaml"
apiVersion: launchhpc.io/v1
kind: CompliancePolicy
metadata:
  name: enterprise-compliance
  namespace: launchhpc-system
spec:
  frameworks:
    - name: 'SOC2'
      enabled: true
      controls:
        - id: 'CC6.1'
          description: 'Logical access controls'
          requirements:
            - 'All workloads must use RBAC'
            - 'MFA required for admin access'
            - 'Session timeout: 8 hours'

    - name: 'HIPAA'
      enabled: true
      controls:
        - id: '164.312(a)(1)'
          description: 'Access controls'
          requirements:
            - 'Data encryption at rest and in transit'
            - 'Audit logging enabled'
            - 'Regular access reviews'

    - name: 'FedRAMP'
      enabled: true
      controls:
        - id: 'AC-2'
          description: 'Account management'
          requirements:
            - 'Automated account provisioning'
            - 'Regular account audits'
            - 'Privileged account monitoring'

  monitoring:
    auditLogs:
      enabled: true
      retention: '7y'
      encryption: true

    violations:
      alerting: true
      autoRemediation: false
      escalation:
        - level: 1
          recipients: ['compliance-team@company.com']
        - level: 2
          recipients: ['ciso@company.com']

  reporting:
    schedule: 'monthly'
    formats: ['pdf', 'json']
    recipients: ['audit-team@company.com']
```

### Automated Reporting

Generate automated compliance and performance reports:

```python title="reporting/report-generator.py"
#!/usr/bin/env python3
"""
LaunchHPC Automated Reporting System
Generates compliance, performance, and cost reports
"""

import asyncio
from datetime import datetime, timedelta
from jinja2 import Template
import pandas as pd
from dataclasses import dataclass
from typing import List, Dict

@dataclass
class WorkloadReport:
    workload_id: str
    workload_type: str
    start_time: datetime
    end_time: datetime
    cost: float
    success_rate: float
    avg_utilization: Dict[str, float]
    compliance_score: float

class ReportGenerator:
    def __init__(self, config: Dict):
        self.config = config
        self.prometheus_client = self._setup_prometheus()
        self.compliance_checker = self._setup_compliance()

    async def generate_monthly_report(self) -> Dict:
        """Generate comprehensive monthly report"""
        end_date = datetime.now()
        start_date = end_date - timedelta(days=30)

        # Collect data
        workloads = await self._get_workload_data(start_date, end_date)
        costs = await self._get_cost_data(start_date, end_date)
        compliance = await self._get_compliance_data(start_date, end_date)
        performance = await self._get_performance_data(start_date, end_date)

        report = {
            "period": {
                "start": start_date.isoformat(),
                "end": end_date.isoformat()
            },
            "summary": {
                "total_workloads": len(workloads),
                "successful_workloads": len([w for w in workloads if w.success_rate > 0.95]),
                "total_cost": sum(costs.values()),
                "avg_compliance_score": sum(w.compliance_score for w in workloads) / len(workloads)
            },
            "workloads": [self._workload_to_dict(w) for w in workloads],
            "cost_analysis": costs,
            "compliance_status": compliance,
            "performance_metrics": performance,
            "recommendations": await self._generate_recommendations(workloads, costs, performance)
        }

        return report

    async def _generate_recommendations(self, workloads: List[WorkloadReport], costs: Dict, performance: Dict) -> List[str]:
        """Generate actionable recommendations based on report data"""
        recommendations = []

        # Cost optimization recommendations
        high_cost_workloads = [w for w in workloads if w.cost > self.config['cost_thresholds']['high']]
        if high_cost_workloads:
            recommendations.append(f"Review {len(high_cost_workloads)} high-cost workloads for optimization opportunities")

        # Performance recommendations
        low_util_workloads = [w for w in workloads if w.avg_utilization.get('cpu', 0) < 50]
        if low_util_workloads:
            recommendations.append(f"Consider downsizing {len(low_util_workloads)} underutilized workloads")

        # Compliance recommendations
        non_compliant = [w for w in workloads if w.compliance_score < 0.9]
        if non_compliant:
            recommendations.append(f"Address compliance issues in {len(non_compliant)} workloads")

        return recommendations

# Usage example
async def main():
    generator = ReportGenerator(config={
        'cost_thresholds': {'high': 1000},
        'prometheus_url': 'http://prometheus:9090'
    })

    report = await generator.generate_monthly_report()
    print(f"Generated report with {len(report['workloads'])} workloads")

if __name__ == "__main__":
    asyncio.run(main())
```

## Alerting & Notifications

### Alert Configuration

Set up intelligent alerting for operational issues:

```yaml title="alerting/alert-rules.yaml"
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: launchhpc-alerts
  namespace: monitoring
spec:
  groups:
    - name: launchhpc.workloads
      rules:
        - alert: WorkloadFailureRate
          expr: |
            (
              rate(launchhpc_workload_completions_total{status="failed"}[5m]) /
              rate(launchhpc_workload_completions_total[5m])
            ) > 0.1
          for: 2m
          labels:
            severity: warning
            component: workload-execution
          annotations:
            summary: 'High workload failure rate detected'
            description: 'Workload failure rate is {{ $value | humanizePercentage }} over the last 5 minutes'

        - alert: HighCostAlert
          expr: sum(rate(launchhpc_workload_cost_usd[1h])) > 100
          for: 5m
          labels:
            severity: warning
            component: cost-management
          annotations:
            summary: 'High hourly cost detected'
            description: 'Current hourly cost is ${{ $value }}'

        - alert: ResourceUtilizationLow
          expr: avg(launchhpc_resource_utilization_percent{resource_type="cpu"}) < 20
          for: 10m
          labels:
            severity: info
            component: resource-optimization
          annotations:
            summary: 'Low CPU utilization across cluster'
            description: 'Average CPU utilization is {{ $value }}%'

    - name: launchhpc.infrastructure
      rules:
        - alert: NodeDown
          expr: up{job="kubernetes-nodes"} == 0
          for: 1m
          labels:
            severity: critical
            component: infrastructure
          annotations:
            summary: 'Node {{ $labels.instance }} is down'

        - alert: PodCrashLooping
          expr: rate(kube_pod_container_status_restarts_total[15m]) > 0
          for: 5m
          labels:
            severity: warning
            component: infrastructure
          annotations:
            summary: 'Pod {{ $labels.pod }} is crash looping'
```

## API Reference

| Endpoint                     | Method | Description                      |
| ---------------------------- | ------ | -------------------------------- |
| `/api/v1/metrics/workloads`  | GET    | Get workload performance metrics |
| `/api/v1/metrics/costs`      | GET    | Get cost analytics data          |
| `/api/v1/metrics/compliance` | GET    | Get compliance status            |
| `/api/v1/reports/generate`   | POST   | Generate custom reports          |
| `/api/v1/alerts/configure`   | POST   | Configure alerting rules         |

### SDK Usage

```typescript
// Monitor workload performance
const metrics = await client.metrics.getWorkloadMetrics({
  timeRange: '24h',
  workloadType: 'ai-training',
  aggregation: 'avg',
});

// Generate cost report
const costReport = await client.reports.generateCostReport({
  period: 'monthly',
  groupBy: ['provider', 'workload_type'],
  includeForecasting: true,
});

// Set up custom alerts
await client.alerts.createAlert({
  name: 'high-gpu-utilization',
  condition: 'avg(gpu_utilization) > 90',
  duration: '5m',
  channels: ['slack', 'email'],
});
```

## Best Practices

> **Monitoring Tip**: Start with basic system metrics and gradually add application-specific metrics as you understand your workload patterns better.

- **Metric Retention** - Configure appropriate retention periods based on compliance requirements
- **Alert Fatigue** - Set meaningful thresholds to avoid excessive alerting
- **Dashboard Design** - Create role-specific dashboards for different stakeholders
- **Cost Tracking** - Implement granular cost attribution using labels and tags
- **Compliance Automation** - Automate compliance checks where possible to reduce manual overhead
- **Performance Baselines** - Establish performance baselines to detect anomalies

<span class="docs-badge">Monitoring Enabled</span>
